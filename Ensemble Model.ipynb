{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580ab100-cd64-4111-858b-f87e0fe885cb",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd7ed5b-a209-41c7-ac99-6c26d4210303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324b253b-bf09-43cd-b2b2-f8931d496d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea98dd9b-bf51-42c4-a704-3704ce0aa1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, num_filters=100, filter_sizes=(3, 4, 5), dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim,\n",
    "                      out_channels=num_filters,\n",
    "                      kernel_size=fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(num_filters * len(filter_sizes), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)           # (batch_size, seq_len, emb_dim)\n",
    "        x = x.permute(0, 2, 1)          # (batch_size, emb_dim, seq_len)\n",
    "        convs = [F.relu(conv(x)) for conv in self.convs]  # list of (batch_size, num_filters, *)\n",
    "        pooled = [F.max_pool1d(c, kernel_size=c.size(2)).squeeze(2) for c in convs]\n",
    "        cat = torch.cat(pooled, dim=1)  # (batch_size, num_filters * len(filter_sizes))\n",
    "        dropped = self.dropout(cat)\n",
    "        logits = self.fc(dropped)\n",
    "        return logits.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b38f4c3-70dd-4566-9fd1-d6d5836432a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(embeds)\n",
    "        forward_final = h_n[-2]\n",
    "        backward_final = h_n[-1]\n",
    "        last_hidden = torch.cat((forward_final, backward_final), dim=1)\n",
    "        logits = self.fc(self.dropout(last_hidden))\n",
    "        return logits.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de88f1fd-dd4c-4d27-881b-d7131b6d78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(9, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be2cd1a0-a73f-4fed-8e10-fd8e63ff2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(token_lists: List[List[int]]) -> List[str]:\n",
    "    return [\" \".join(map(str, tokens)) for tokens in token_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0f64e3-f5f6-4e3b-9ed0-7cac3d847a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_lines(path):\n",
    "    texts, labels = [], []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            ex = json.loads(line)\n",
    "            texts.append(torch.tensor(ex['text'], dtype=torch.long))\n",
    "            labels.append(ex['label'])\n",
    "    return texts, labels\n",
    "\n",
    "def load_test_json(path):\n",
    "    texts = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            ex = json.loads(line)\n",
    "            texts.append(torch.tensor(ex['text'], dtype=torch.long))\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0acb7af3-4442-4ef1-97c5-11cb244d5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_and_pad_sequences(sequences: List[torch.Tensor], max_len: int, padding_value: int = 0) -> torch.Tensor:\n",
    "    \"\"\"Truncate and pad a list of token sequences to the same max length.\"\"\"\n",
    "    truncated = [seq[:max_len] for seq in sequences]\n",
    "    return pad_sequence(truncated, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "def prepare_tensor_sequences(raw_seqs: List[List[int]], max_len: int) -> torch.Tensor:\n",
    "    token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n",
    "    return truncate_and_pad_sequences(token_tensors, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75347502-119e-41a5-a260-d323637d2592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embed_stats(token_lists: List[List[int]], embedding_matrix: np.ndarray) -> np.ndarray:\n",
    "    stats = []\n",
    "    for tokens in token_lists:\n",
    "        embedded = np.array([embedding_matrix[t] for t in tokens if t < len(embedding_matrix)])\n",
    "        if embedded.size == 0:\n",
    "            mean = np.zeros(embedding_matrix.shape[1])\n",
    "            std = np.zeros(embedding_matrix.shape[1])\n",
    "        else:\n",
    "            mean = embedded.mean(axis=0)\n",
    "            std = embedded.std(axis=0)\n",
    "        stats.append(np.concatenate([mean, std]))\n",
    "    return np.vstack(stats)\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4bc46f0-9590-4293-a902-5bd1cff585b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weighted_sampler(domains, labels):\n",
    "    from collections import defaultdict\n",
    "    from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "    # Group by (domain, label)\n",
    "    group_to_indices = defaultdict(list)\n",
    "    for i, (d, l) in enumerate(zip(domains, labels)):\n",
    "        group_to_indices[(d, l)].append(i)\n",
    "\n",
    "    # Find the max group size\n",
    "    max_group_size = max(len(v) for v in group_to_indices.values())\n",
    "\n",
    "    # Create weights so each group contributes equally\n",
    "    weights = [0] * len(labels)\n",
    "    for group, indices in group_to_indices.items():\n",
    "        group_weight = max_group_size / len(indices)\n",
    "        for i in indices:\n",
    "            weights[i] = group_weight\n",
    "\n",
    "    sample_weights = torch.DoubleTensor(weights)\n",
    "    sampler = WeightedRandomSampler(sample_weights, len(labels), replacement=True)\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae61815c-e2a6-4d66-981e-041788424687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_train_val_split(texts, labels, domains, val_size_per_group=60, random_state=42):\n",
    "    random.seed(random_state)\n",
    "    from collections import defaultdict\n",
    "    buckets = defaultdict(list)\n",
    "\n",
    "    for x, y, d in zip(texts, labels, domains):\n",
    "        buckets[(d, y)].append((x, y, d))\n",
    "\n",
    "    train, val = [], []\n",
    "    for key in buckets:\n",
    "        group = buckets[key]\n",
    "        random.shuffle(group)\n",
    "        n_val = min(val_size_per_group, len(group))\n",
    "        val.extend(group[:n_val])\n",
    "        train.extend(group[n_val:])\n",
    "\n",
    "    random.shuffle(train)\n",
    "    random.shuffle(val)\n",
    "    tx, ty, td = zip(*train)\n",
    "    vx, vy, vd = zip(*val)\n",
    "    return list(tx), list(ty), list(td), list(vx), list(vy), list(vd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bd82ca0-2a20-4c8a-8968-aa8cdf5fa9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfold_by_domain_label(texts, labels, domains, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Custom stratified K-Fold by (domain, label) pair.\n",
    "    Returns list of (train_indices, val_indices) for each fold.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    buckets = defaultdict(list)\n",
    "\n",
    "    for idx, (d, l) in enumerate(zip(domains, labels)):\n",
    "        buckets[(d, l)].append(idx)\n",
    "\n",
    "    for key in buckets:\n",
    "        rng.shuffle(buckets[key])\n",
    "\n",
    "    folds = [[] for _ in range(n_splits)]\n",
    "    for key, idxs in buckets.items():\n",
    "        for i, idx in enumerate(idxs):\n",
    "            folds[i % n_splits].append(idx)\n",
    "\n",
    "    fold_indices = []\n",
    "    for i in range(n_splits):\n",
    "        val_idx = folds[i]\n",
    "        train_idx = [idx for j in range(n_splits) if j != i for idx in folds[j]]\n",
    "        fold_indices.append((train_idx, val_idx))\n",
    "\n",
    "    return fold_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "283937b9-54d6-4bc5-ac6b-33bbf821acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, lr, device=\"cpu\"):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    pos_weight = torch.tensor([\n",
    "        sum(1 for y in train_loader.dataset.tensors[1] if y == 0) /\n",
    "        sum(1 for y in train_loader.dataset.tensors[1] if y == 1)\n",
    "    ], device=device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch} — Train Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a622eb6-7b55-47c8-a9ea-9a028979c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_confidence(model, dataloader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    preds, probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting\", leave=False):\n",
    "            if len(batch) == 2:\n",
    "                X_batch, _ = batch  # Ignore labels\n",
    "            else:\n",
    "                X_batch = batch[0]\n",
    "            X_batch = X_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            batch_probs = torch.sigmoid(logits).squeeze()\n",
    "\n",
    "            if batch_probs.ndim == 0:\n",
    "                batch_probs = batch_probs.unsqueeze(0)\n",
    "\n",
    "            batch_preds = (batch_probs >= 0.5).int().tolist()\n",
    "            preds.extend(batch_preds)\n",
    "            probs.extend(batch_probs.cpu().tolist())\n",
    "\n",
    "    return preds, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71f87874-7077-46d3-96c9-3c1c63edd0d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.2078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/1017881018.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_tensors = [torch.tensor(seq, dtype=torch.long) for seq in raw_seqs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Training] Fold 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train Loss: 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Train Loss: 0.1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Train Loss: 0.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Train Loss: 0.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Train Loss: 0.0558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 — Train Loss: 0.0473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    }
   ],
   "source": [
    "# === Step 0: Load and Split Data ===\n",
    "d1_texts, d1_labels = load_json_lines(\"data/domain1_train_data.json\")\n",
    "d2_texts, d2_labels = load_json_lines(\"data/domain2_train_data.json\")\n",
    "texts = d1_texts + d2_texts\n",
    "labels = d1_labels + d2_labels\n",
    "domains = [0] * len(d1_labels) + [1] * len(d2_labels)\n",
    "MAX_LEN = 2048\n",
    "num_folds = 10\n",
    "\n",
    "test_texts_raw = load_test_json(\"data/test_data.json\")\n",
    "test_texts = prepare_tensor_sequences(test_texts_raw, MAX_LEN)\n",
    "\n",
    "test_dataset_cnn = TensorDataset(test_texts)\n",
    "test_loader_cnn = DataLoader(test_dataset_cnn, batch_size=32)\n",
    "\n",
    "# === Step 6: Generate Out-of-Fold Predictions for Meta-Classifier ===\n",
    "meta_inputs = []\n",
    "meta_targets = []\n",
    "bilstm_val_preds_all = []\n",
    "cnn_val_preds_all = []\n",
    "mlp_val_preds_all = []\n",
    "\n",
    "fold_indices = stratified_kfold_by_domain_label(texts, labels, domains, n_splits=10)\n",
    "for fold, (train_idx, val_idx) in enumerate(fold_indices):\n",
    "    print(f\"[Meta Training] Fold {fold + 1}/{num_folds}\")\n",
    "    fold_train_texts = [texts[i] for i in train_idx]\n",
    "    fold_val_texts = [texts[i] for i in val_idx]\n",
    "    fold_train_labels = [labels[i] for i in train_idx]\n",
    "    fold_val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    # Prepare padded CNN input\n",
    "    fold_train_padded = prepare_tensor_sequences(fold_train_texts, MAX_LEN)\n",
    "    fold_val_padded = prepare_tensor_sequences(fold_val_texts, MAX_LEN)\n",
    "\n",
    "    # CNN\n",
    "    cnn_model = CNNTextClassifier(\n",
    "        vocab_size=17120,\n",
    "        embedding_dim=128,\n",
    "        num_filters=50,\n",
    "        filter_sizes=(2, 3, 4),\n",
    "        dropout=0.5\n",
    "    ).to(device)\n",
    "    fold_train_domains = [domains[i] for i in train_idx]\n",
    "    cnn_loader = DataLoader(\n",
    "        TensorDataset(fold_train_padded, torch.tensor(fold_train_labels, dtype=torch.float32)),\n",
    "        batch_size=32,\n",
    "        sampler=create_weighted_sampler(fold_train_domains, fold_train_labels)\n",
    "    )\n",
    "    train(cnn_model, cnn_loader, epochs=4, lr=0.001, device=device)\n",
    "\n",
    "    val_loader_cnn = DataLoader(TensorDataset(fold_val_padded), batch_size=32)\n",
    "    cnn_probs = np.array(predict_with_confidence(cnn_model, val_loader_cnn, device=device)[1])\n",
    "\n",
    "    # BiLSTM\n",
    "    bilstm_model = BiLSTMClassifier(\n",
    "        vocab_size=17120,\n",
    "        hidden_dim=128,\n",
    "        num_layers=1,\n",
    "        dropout=0.5\n",
    "    ).to(device)\n",
    "    bilstm_loader = DataLoader(\n",
    "        TensorDataset(fold_train_padded, torch.tensor(fold_train_labels, dtype=torch.float32)),\n",
    "        batch_size=32,\n",
    "        sampler=create_weighted_sampler(fold_train_domains, fold_train_labels)\n",
    "    )\n",
    "    train(bilstm_model, bilstm_loader, epochs=5, lr=0.0005, device=device)\n",
    "\n",
    "    val_loader_bilstm = DataLoader(TensorDataset(fold_val_padded), batch_size=32)\n",
    "    bilstm_probs = np.array(predict_with_confidence(bilstm_model, val_loader_bilstm, device=device)[1])\n",
    "    \n",
    "    #MLP\n",
    "    fold_val_strings = tokens_to_text(fold_val_texts)\n",
    "    fold_train_strings = tokens_to_text(fold_train_texts)\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=5000)\n",
    "    X_train_tfidf = tfidf.fit_transform(fold_train_strings).toarray()\n",
    "    X_val_tfidf = tfidf.transform(fold_val_strings).toarray()\n",
    "\n",
    "    svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "    X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "    X_val_svd = svd.transform(X_val_tfidf)\n",
    "\n",
    "    X_train_raw = np.hstack([X_train_svd])\n",
    "    X_val_raw = np.hstack([X_val_svd])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train_raw)\n",
    "    X_val_std = scaler.transform(X_val_raw)\n",
    "\n",
    "    mlp_model = MLPClassifier(input_dim=X_train_std.shape[1], hidden_dim=256, dropout=0.5).to(device)\n",
    "    train_loader_mlp = DataLoader(\n",
    "        TensorDataset(torch.tensor(X_train_std, dtype=torch.float32), torch.tensor(fold_train_labels, dtype=torch.float32)),\n",
    "        batch_size=64,\n",
    "        sampler=create_weighted_sampler(fold_train_domains, fold_train_labels)\n",
    "    )\n",
    "    train(mlp_model, train_loader_mlp, epochs=6, lr=1e-3, device=device)\n",
    "\n",
    "    val_loader_mlp = DataLoader(TensorDataset(torch.tensor(X_val_std, dtype=torch.float32)), batch_size=64)\n",
    "    mlp_probs = np.array(predict_with_confidence(mlp_model, val_loader_mlp, device=device)[1])\n",
    "\n",
    "    fold_meta = np.vstack([\n",
    "        cnn_probs,\n",
    "        (cnn_probs >= 0.5).astype(float),\n",
    "        np.abs(cnn_probs - 0.5),\n",
    "        mlp_probs,\n",
    "        (mlp_probs >= 0.5).astype(float),\n",
    "        np.abs(mlp_probs - 0.5),\n",
    "        bilstm_probs,\n",
    "        (bilstm_probs >= 0.5).astype(float),\n",
    "        np.abs(bilstm_probs - 0.5)\n",
    "    ]).T\n",
    "    bilstm_val_preds_all.append((bilstm_probs >= 0.5).astype(int))\n",
    "    cnn_val_preds_all.append((cnn_probs >= 0.5).astype(int))\n",
    "    mlp_val_preds_all.append((mlp_probs >= 0.5).astype(int))\n",
    "    meta_inputs.append(fold_meta)\n",
    "    meta_targets.extend(fold_val_labels)\n",
    "\n",
    "X_meta_val = np.vstack(meta_inputs)\n",
    "y_meta_val = np.array(meta_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69dbd736-cbf8-4976-a3ed-8c992b39098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/q4lnp11x0dz2_w8bl88s6hwh0000gn/T/ipykernel_90363/2914117806.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  X_meta_train_tensor = torch.tensor(meta_train_texts, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetaNN] Epoch 1 — Train Loss: 0.1189 — Val Acc: 0.8396\n",
      "[MetaNN] Epoch 2 — Train Loss: 0.0886 — Val Acc: 0.8562\n",
      "[MetaNN] Epoch 3 — Train Loss: 0.0638 — Val Acc: 0.9146\n",
      "[MetaNN] Epoch 4 — Train Loss: 0.0532 — Val Acc: 0.9146\n",
      "[MetaNN] Epoch 5 — Train Loss: 0.0475 — Val Acc: 0.9167\n",
      "[MetaNN] Epoch 6 — Train Loss: 0.0463 — Val Acc: 0.9167\n",
      "[MetaNN] Epoch 7 — Train Loss: 0.0474 — Val Acc: 0.9167\n",
      "[MetaNN] Epoch 8 — Train Loss: 0.0466 — Val Acc: 0.9167\n",
      "[MetaNN] Epoch 9 — Train Loss: 0.0451 — Val Acc: 0.9187\n",
      "[MetaNN] Epoch 10 — Train Loss: 0.0468 — Val Acc: 0.9187\n",
      "[MetaNN] Epoch 11 — Train Loss: 0.0455 — Val Acc: 0.9187\n",
      "[MetaNN] Epoch 12 — Train Loss: 0.0485 — Val Acc: 0.9187\n",
      "[MetaNN] Epoch 13 — Train Loss: 0.0471 — Val Acc: 0.9187\n",
      "[MetaNN] Epoch 14 — Train Loss: 0.0470 — Val Acc: 0.9187\n",
      "Early stopping.\n",
      "\n",
      "MetaNN Overall Validation Accuracy: 0.9187\n",
      "\n",
      "MetaNN Validation Accuracy by Domain:\n",
      "  Domain 0: 0.9167\n",
      "  Domain 1: 0.9208\n",
      "\n",
      "Base Model Overall Validation Accuracy:\n",
      "  CNN Accuracy: 0.8733333333333333\n",
      "  BiLSTM Accuracy: 0.8731666666666666\n",
      "  MLP Accuracy: 0.8225\n",
      "\n",
      "Base Model Validation Accuracy by Domain:\n",
      "  Domain 0:\n",
      "    CNN Accuracy: 0.917\n",
      "    BiLSTM Accuracy: 0.828\n",
      "    MLP Accuracy: 0.878\n",
      "  Domain 1:\n",
      "    CNN Accuracy: 0.8646\n",
      "    BiLSTM Accuracy: 0.8822\n",
      "    MLP Accuracy: 0.8114\n"
     ]
    }
   ],
   "source": [
    "# === Step 7a: Train and Validate MetaNN ===\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create stratified split for meta-training\n",
    "meta_domains = [domains[i] for _, val_idx in fold_indices for i in val_idx]\n",
    "meta_texts = list(X_meta_val)\n",
    "meta_labels = list(y_meta_val)\n",
    "\n",
    "meta_train_texts, meta_train_labels, meta_train_domains, meta_val_texts, meta_val_labels, meta_val_domains = stratified_train_val_split(\n",
    "    meta_texts, meta_labels, meta_domains, val_size_per_group=120, random_state=42\n",
    ")\n",
    "meta_val_domains = np.array(meta_val_domains)\n",
    "\n",
    "X_meta_train_tensor = torch.tensor(meta_train_texts, dtype=torch.float32).to(device)\n",
    "y_meta_train_tensor = torch.tensor(meta_train_labels, dtype=torch.float32).to(device)\n",
    "X_meta_valid_tensor = torch.tensor(meta_val_texts, dtype=torch.float32).to(device)\n",
    "y_meta_valid_tensor = torch.tensor(meta_val_labels, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define MetaNN\n",
    "meta_nn = MetaNN().to(device)\n",
    "optimizer_meta = torch.optim.Adam(meta_nn.parameters(), lr=1e-3)\n",
    "pos_weight = torch.tensor([(y_meta_train_tensor == 0).sum() / (y_meta_train_tensor == 1).sum()], device=device)\n",
    "criterion_meta = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "#meta_sampler = create_weighted_sampler(meta_train_domains, meta_train_labels)\n",
    "#meta_loader = DataLoader(\n",
    " #   TensorDataset(X_meta_train_tensor, y_meta_train_tensor),\n",
    "  #  batch_size=64,\n",
    "   # sampler=meta_sampler\n",
    "#)\n",
    "\n",
    "meta_loader = DataLoader(TensorDataset(X_meta_train_tensor, y_meta_train_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "# Early stopping\n",
    "best_val_acc = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    meta_nn.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in meta_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer_meta.zero_grad()\n",
    "        logits = meta_nn(X_batch)\n",
    "        loss = criterion_meta(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_meta.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    meta_nn.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = meta_nn(X_meta_valid_tensor)\n",
    "        val_probs = torch.sigmoid(val_logits).cpu().numpy()\n",
    "        val_preds = (val_probs >= 0.5).astype(int)\n",
    "        val_acc = accuracy_score(y_meta_valid_tensor.cpu().numpy(), val_preds)\n",
    "\n",
    "    print(f\"[MetaNN] Epoch {epoch} — Train Loss: {total_loss / len(meta_loader):.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = meta_nn.state_dict()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "meta_nn.load_state_dict(best_state)\n",
    "\n",
    "# Evaluate MetaNN against early stopping validation split\n",
    "meta_nn.eval()\n",
    "with torch.no_grad():\n",
    "    val_logits = meta_nn(X_meta_valid_tensor)\n",
    "    val_probs = torch.sigmoid(val_logits).cpu().numpy()\n",
    "    val_preds = (val_probs >= 0.5).astype(int)\n",
    "\n",
    "meta_val_acc = accuracy_score(np.array(meta_val_labels), val_preds)\n",
    "print(f\"\\nMetaNN Overall Validation Accuracy: {meta_val_acc:.4f}\")\n",
    "\n",
    "print(\"\\nMetaNN Validation Accuracy by Domain:\")\n",
    "for domain_id in [0, 1]:\n",
    "    mask = (meta_val_domains == domain_id)\n",
    "    domain_acc = accuracy_score(np.array(meta_val_labels)[mask], val_preds[mask])\n",
    "    print(f\"  Domain {domain_id}: {domain_acc:.4f}\")\n",
    "\n",
    "# Evaluate base models by domain using full out-of-fold meta-validation set\n",
    "cnn_val_preds = np.concatenate(cnn_val_preds_all)\n",
    "mlp_val_preds = np.concatenate(mlp_val_preds_all)\n",
    "bilstm_val_preds = np.concatenate(bilstm_val_preds_all)\n",
    "full_meta_val_domains = np.array([domains[i] for _, val_idx in fold_indices for i in val_idx])\n",
    "y_meta_val = np.array(meta_labels)\n",
    "\n",
    "print(\"\\nBase Model Overall Validation Accuracy:\")\n",
    "print(\"  CNN Accuracy:\", accuracy_score(y_meta_val, cnn_val_preds))\n",
    "print(\"  BiLSTM Accuracy:\", accuracy_score(y_meta_val, bilstm_val_preds))\n",
    "print(\"  MLP Accuracy:\", accuracy_score(y_meta_val, mlp_val_preds))\n",
    "\n",
    "print(\"\\nBase Model Validation Accuracy by Domain:\")\n",
    "for domain_id in [0, 1]:\n",
    "    mask = (full_meta_val_domains == domain_id)\n",
    "    print(f\"  Domain {domain_id}:\")\n",
    "    print(\"    CNN Accuracy:\", accuracy_score(y_meta_val[mask], cnn_val_preds[mask]))\n",
    "    print(\"    BiLSTM Accuracy:\", accuracy_score(y_meta_val[mask], bilstm_val_preds[mask]))\n",
    "    print(\"    MLP Accuracy:\", accuracy_score(y_meta_val[mask], mlp_val_preds[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "221e1c40-723c-4256-8fa9-025e604ac855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetaNN] Epoch 1 — Train Loss: 0.1514\n",
      "[MetaNN] Epoch 2 — Train Loss: 0.1123\n",
      "[MetaNN] Epoch 3 — Train Loss: 0.0859\n",
      "[MetaNN] Epoch 4 — Train Loss: 0.0718\n",
      "[MetaNN] Epoch 5 — Train Loss: 0.0638\n",
      "[MetaNN] Epoch 6 — Train Loss: 0.0598\n",
      "[MetaNN] Epoch 7 — Train Loss: 0.0586\n",
      "[MetaNN] Epoch 8 — Train Loss: 0.0556\n",
      "[MetaNN] Epoch 9 — Train Loss: 0.0556\n",
      "[MetaNN] Epoch 10 — Train Loss: 0.0550\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# === Full MLP Training ===\u001b[39;00m\n\u001b[1;32m     43\u001b[0m full_text_strings \u001b[38;5;241m=\u001b[39m tokens_to_text(full_texts)\n\u001b[0;32m---> 44\u001b[0m X_full_tfidf \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241m.\u001b[39mfit_transform(full_text_strings)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m     45\u001b[0m X_test_tfidf \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(test_text_strings)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m     47\u001b[0m X_full_svd \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(X_full_tfidf)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# === Step 7: Retrain Models on Full Data for Final Ensemble ===\n",
    "\n",
    "# === Train MetaNN on Full Meta-Training Set ===\n",
    "meta_nn = MetaNN().to(device)\n",
    "optimizer_meta = torch.optim.Adam(meta_nn.parameters(), lr=1e-3)\n",
    "\n",
    "pos_weight = torch.tensor([\n",
    "    (y_meta_val == 0).sum() / (y_meta_val == 1).sum()\n",
    "], device=device)\n",
    "criterion_meta = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "X_meta_val_tensor = torch.tensor(X_meta_val, dtype=torch.float32).to(device)\n",
    "y_meta_val_tensor = torch.tensor(y_meta_val, dtype=torch.float32).to(device)\n",
    "\n",
    "#meta_sampler = create_weighted_sampler(meta_domains, y_meta_val)\n",
    "#meta_loader = DataLoader(\n",
    "   # TensorDataset(X_meta_val_tensor, y_meta_val_tensor),\n",
    "  #  batch_size=64,\n",
    " #   sampler=meta_sampler\n",
    "#)\n",
    "\n",
    "meta_loader = DataLoader(TensorDataset(X_meta_train_tensor, y_meta_train_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    total_loss = 0.0\n",
    "    meta_nn.train()\n",
    "    for X_batch, y_batch in meta_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer_meta.zero_grad()\n",
    "        logits = meta_nn(X_batch)\n",
    "        loss = criterion_meta(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_meta.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"[MetaNN] Epoch {epoch} — Train Loss: {total_loss / len(meta_loader):.4f}\")\n",
    "\n",
    "full_texts = texts\n",
    "full_labels = labels\n",
    "full_domains = domains\n",
    "\n",
    "# === Full MLP Training ===\n",
    "full_text_strings = tokens_to_text(full_texts)\n",
    "X_full_tfidf = tfidf_vectorizer.fit_transform(full_text_strings).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_text_strings).toarray()\n",
    "\n",
    "X_full_svd = svd.fit_transform(X_full_tfidf)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "X_full_raw = np.hstack([X_full_svd])\n",
    "X_test_raw = np.hstack([X_test_svd])\n",
    "\n",
    "X_full_std = scaler.fit_transform(X_full_raw)\n",
    "X_test_std = scaler.transform(X_test_raw)\n",
    "\n",
    "X_full_tensor = torch.tensor(X_full_std, dtype=torch.float32)\n",
    "y_full_tensor = torch.tensor(full_labels, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_std, dtype=torch.float32)\n",
    "\n",
    "full_dataset_mlp = TensorDataset(X_full_tensor, y_full_tensor)\n",
    "full_loader_mlp = DataLoader(full_dataset_mlp, batch_size=64, sampler=create_weighted_sampler(full_domains, full_labels))\n",
    "test_loader_mlp = DataLoader(TensorDataset(X_test_tensor), batch_size=64)\n",
    "\n",
    "mlp_model = MLPClassifier(input_dim=X_full_tensor.shape[1], hidden_dim=256, dropout=0.5).to(device)\n",
    "train(mlp_model, full_loader_mlp, epochs=6, lr=1e-3, device=device)\n",
    "\n",
    "# === Full BiLSTM Training ===\n",
    "full_texts_padded = prepare_tensor_sequences(full_texts, MAX_LEN)\n",
    "full_dataset_bilstm = TensorDataset(full_texts_padded, torch.tensor(full_labels, dtype=torch.float32))\n",
    "full_loader_bilstm = DataLoader(full_dataset_bilstm, batch_size=32, sampler=create_weighted_sampler(full_domains, full_labels))\n",
    "\n",
    "bilstm_model = BiLSTMClassifier(\n",
    "    vocab_size=17120,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "train(bilstm_model, full_loader_bilstm, epochs=5, lr=0.0005, device=device)\n",
    "\n",
    "# === Full CNN Training ===\n",
    "full_texts_padded = prepare_tensor_sequences(full_texts, MAX_LEN)\n",
    "full_dataset_cnn = TensorDataset(full_texts_padded, torch.tensor(full_labels, dtype=torch.float32))\n",
    "full_loader_cnn = DataLoader(full_dataset_cnn, batch_size=32, sampler=create_weighted_sampler(full_domains, full_labels))\n",
    "\n",
    "cnn_model = CNNTextClassifier(\n",
    "    vocab_size=17120,\n",
    "    embedding_dim=128,\n",
    "    num_filters=50,\n",
    "    filter_sizes=(2, 3, 4),\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "train(cnn_model, full_loader_cnn, epochs=4, lr=0.001, device=device)\n",
    "\n",
    "test_dataset_cnn = TensorDataset(test_texts)\n",
    "test_loader_cnn = DataLoader(test_dataset_cnn, batch_size=32)\n",
    "\n",
    "# === Step 8: Predict on Test and Use Meta-Classifier ===\n",
    "bilstm_test_preds, bilstm_test_probs = predict_with_confidence(bilstm_model, test_loader_cnn, device=device)\n",
    "mlp_test_preds, mlp_test_probs = predict_with_confidence(mlp_model, test_loader_mlp, device=device)\n",
    "cnn_test_preds, cnn_test_probs = predict_with_confidence(cnn_model, test_loader_cnn, device=device)\n",
    "\n",
    "cnn_test_probs = np.array(cnn_test_probs)\n",
    "mlp_test_probs = np.array(mlp_test_probs)\n",
    "bilstm_test_probs = np.array(bilstm_test_probs)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"id\": list(range(len(cnn_test_preds))),\n",
    "    \"label\": cnn_test_preds\n",
    "}).to_csv(\"cnn_submission.csv\", index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"id\": list(range(len(mlp_test_preds))),\n",
    "    \"label\": mlp_test_preds\n",
    "}).to_csv(\"mlp_submission.csv\", index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"id\": list(range(len(bilstm_test_preds))),\n",
    "    \"label\": bilstm_test_preds\n",
    "}).to_csv(\"bilstm_submission.csv\", index=False)\n",
    "\n",
    "X_meta_test = np.vstack([\n",
    "        cnn_test_probs,\n",
    "        (cnn_test_probs >= 0.5).astype(float),\n",
    "        np.abs(cnn_test_probs - 0.5),\n",
    "        mlp_test_probs,\n",
    "        (mlp_test_probs >= 0.5).astype(float),\n",
    "        np.abs(mlp_test_probs - 0.5),\n",
    "        bilstm_test_probs,\n",
    "        (bilstm_test_probs >= 0.5).astype(float),\n",
    "        np.abs(bilstm_test_probs - 0.5)\n",
    "    ]).T\n",
    "\n",
    "X_meta_test_tensor = torch.tensor(X_meta_test, dtype=torch.float32).to(device)\n",
    "meta_nn.eval()\n",
    "with torch.no_grad():\n",
    "    logits = meta_nn(X_meta_test_tensor)\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "ensemble_probs = probs\n",
    "ensemble_preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"id\": list(range(len(ensemble_preds))),\n",
    "    \"label\": ensemble_preds.astype(int),\n",
    "    \"confidence\": ensemble_probs.flatten()\n",
    "})\n",
    "\n",
    "# === Step 9: Save Predictions ===\n",
    "results_df.to_csv(\"ensemble_submission_final.csv\", index=False)\n",
    "results_df[[\"id\", \"label\"]].to_csv(\"ensemble_labels_final.csv\", index=False)\n",
    "print(\"Final ensemble predictions saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
